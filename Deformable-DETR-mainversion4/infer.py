import torch
import torchvision.transforms as T
from PIL import Image
import matplotlib.pyplot as plt
import argparse
from models import deformable_detr  # æ”¹æˆdeformable_detr
import os
from glob import glob



def load_model_from_checkpoint(checkpoint_path, device):
    # å…è®¸ååºåˆ—åŒ– argparse.Namespace
    torch.serialization.add_safe_globals([argparse.Namespace])
    
    ckpt = torch.load(checkpoint_path, map_location=device, weights_only=False)
    args = ckpt['args']
    args.device = device
    
    # æ„å»ºæ¨¡å‹
    model, _, _ = deformable_detr.build(args)  # æ”¹æˆdeformable_detr
    model.load_state_dict(ckpt['model'])
    model.to(device)
    model.eval()
    
    print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼")
    return model


def preprocess(image_path):
    img = Image.open(image_path).convert("RGB")
    transform = T.Compose([
        T.Resize(800),
        T.ToTensor(),
        T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
    return transform(img).unsqueeze(0), img


def postprocess(outputs, img, threshold=0.60):  # SARèˆ¹èˆ¶é˜ˆå€¼è°ƒé«˜ç‚¹
    """å°†Deformable DETRè¾“å‡ºè½¬æ¢ä¸ºåƒç´ åæ ‡"""
    # å–æœ€åä¸€å±‚çš„è¾“å‡º
    logits = outputs['pred_logits'][0]  
    boxes = outputs['pred_boxes'][0]
    
    # è®¡ç®—æ¦‚ç‡ï¼ˆåªæœ‰shipä¸€ä¸ªç±»ï¼‰
    probs = logits.sigmoid()  # [num_queries, 1]
    scores = probs.squeeze(-1)  # [num_queries]
    
    # è¿‡æ»¤ä½åˆ†æ¡†
    keep = scores > threshold
    boxes = boxes[keep]
    scores = scores[keep]
    
    # è½¬æ¢åæ ‡ï¼šcx,cy,w,h -> x1,y1,x2,y2
    w, h = img.size
    boxes_xyxy = torch.zeros_like(boxes)
    boxes_xyxy[:, 0] = (boxes[:, 0] - boxes[:, 2]/2) * w  # x1
    boxes_xyxy[:, 1] = (boxes[:, 1] - boxes[:, 3]/2) * h  # y1
    boxes_xyxy[:, 2] = (boxes[:, 0] + boxes[:, 2]/2) * w  # x2
    boxes_xyxy[:, 3] = (boxes[:, 1] + boxes[:, 3]/2) * h  # y2
    
    return boxes_xyxy.cpu().numpy(), scores.cpu().numpy()


def plot_results(img, boxes, scores, save_path="result.jpg"):
    plt.figure(figsize=(12, 8))
    plt.imshow(img)
    ax = plt.gca()
    
    for (x1, y1, x2, y2), score in zip(boxes, scores):
        rect = plt.Rectangle((x1, y1), x2-x1, y2-y1,
                           fill=False, color='red', linewidth=2)
        ax.add_patch(rect)
        ax.text(x1, y1-5, f'Ship: {score:.2f}', 
                bbox=dict(facecolor='red', alpha=0.5),
                fontsize=10, color='white')
    
    plt.axis('off')
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    print(f"âœ… æ£€æµ‹åˆ° {len(boxes)} ä¸ªç›®æ ‡ï¼Œç»“æœä¿å­˜åˆ° {save_path}")
    plt.close()



if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('--img', default=None, help='path to a single input image')
    # parser.add_argument('--img_dir', default='/root/Deformable-DETR-mainversion4/data/hrsid_coco/val2017', help='/root/Deformable-DETR-mainversion3/data/hrsid_coco/train2017')
    parser.add_argument('--img_dir', default='/root/Deformable-DETR-mainversion4/final-data', help='path of image')
    parser.add_argument('--checkpoint', default="/root/Deformable-DETR-mainversion4/exps/r50_deformable_detr/checkpoint0099.pth", help='path to model checkpoint')
    parser.add_argument('--threshold', type=float, default=0.40, help='confidence threshold')
    parser.add_argument('--out', default="/root/Deformable-DETR-mainversion4/valPicture", help='path to save output image (for single image)')
    parser.add_argument('--out_dir', default='/root/Deformable-DETR-mainversion4/LZCtest02', help='directory to save batch results')

    args = parser.parse_args()
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # åŠ è½½æ¨¡å‹
    model = load_model_from_checkpoint(args.checkpoint, device)

    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.out_dir, exist_ok=True)

    '''
    # æ‰¹é‡æ¨ç†æ¨¡å¼
    if args.img_dir:
        img_paths = sorted(glob(os.path.join(args.img_dir, '*.[jpJP][pnPN]*[gG]')))
        print(f"ğŸ“‚ å…±æ‰¾åˆ° {len(img_paths)} å¼ å›¾ç‰‡ï¼Œå¼€å§‹æ¨ç†...")

        for img_path in img_paths:
            try:
                img_tensor, img = preprocess(img_path)
                with torch.no_grad():
                    outputs = model(img_tensor.to(device))
                boxes, scores = postprocess(outputs, img, threshold=args.threshold)

                # æ„å»ºè¾“å‡ºè·¯å¾„
                filename = os.path.splitext(os.path.basename(img_path))[0] + '.png'
                save_path = os.path.join(args.out_dir, filename)
                plot_results(img, boxes, scores, save_path=save_path)
            except Exception as e:
                print(f"âŒ å¤„ç†å¤±è´¥ï¼š{img_path}ï¼Œé”™è¯¯ï¼š{e}")
    '''
    # æ‰¹é‡æ¨ç†æ¨¡å¼
    if args.img_dir:
        img_paths = sorted(glob(os.path.join(args.img_dir, '*.[jpJP][pnPN]*[gG]')))
        print(f"ğŸ“‚ å…±æ‰¾åˆ° {len(img_paths)} å¼ å›¾ç‰‡ï¼Œå¼€å§‹æ¨ç†...")

        exceptions = []  # ç”¨äºè®°å½•æœªæ£€æµ‹åˆ°ç›®æ ‡çš„å›¾ç‰‡è·¯å¾„

        for img_path in img_paths:
            try:
                img_tensor, img = preprocess(img_path)
                with torch.no_grad():
                    outputs = model(img_tensor.to(device))
                boxes, scores = postprocess(outputs, img, threshold=args.threshold)

                # æ„å»ºè¾“å‡ºè·¯å¾„
                filename = os.path.splitext(os.path.basename(img_path))[0] + '.png'
                save_path = os.path.join(args.out_dir, filename)
                plot_results(img, boxes, scores, save_path=save_path)

                # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°ç›®æ ‡ï¼Œè®°å½•è·¯å¾„
                if len(boxes) == 0:
                    exceptions.append(img_path)

            except Exception as e:
                print(f"âŒ å¤„ç†å¤±è´¥ï¼š{img_path}ï¼Œé”™è¯¯ï¼š{e}")
                exceptions.append(f"{img_path} [ERROR: {e}]")

        # å†™å…¥å¼‚å¸¸å›¾ç‰‡è·¯å¾„
        if exceptions:
            exception_file = os.path.join(args.out_dir, "exception.txt")
            with open(exception_file, "w") as f:
                for path in exceptions:
                    f.write(path + "\n")
            print(f"âš ï¸ å…± {len(exceptions)} å¼ å›¾ç‰‡æœªæ£€æµ‹åˆ°ç›®æ ‡ï¼Œå·²è®°å½•åˆ° {exception_file}")
        else:
            print("ğŸ‰ æ‰€æœ‰å›¾ç‰‡å‡æ£€æµ‹åˆ°ç›®æ ‡ï¼Œæ— å¼‚å¸¸å›¾ç‰‡ã€‚")

    # å•å›¾æ¨ç†æ¨¡å¼
    elif args.img:
        img_tensor, img = preprocess(args.img)
        with torch.no_grad():
            outputs = model(img_tensor.to(device))
        boxes, scores = postprocess(outputs, img, threshold=args.threshold)
        plot_results(img, boxes, scores, save_path=args.out)

    else:
        print("è¯·æä¾› --img æˆ– --img_dir å‚æ•°")
